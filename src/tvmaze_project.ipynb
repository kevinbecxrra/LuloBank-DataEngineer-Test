{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from ydata_profiling import ProfileReport\n",
    "from urllib.parse import urlparse\n",
    "import sqlite3\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos guardados correctamente para la fecha 2024-01-01.\n",
      "Datos guardados correctamente para la fecha 2024-01-02.\n",
      "Datos guardados correctamente para la fecha 2024-01-03.\n",
      "Datos guardados correctamente para la fecha 2024-01-04.\n",
      "Datos guardados correctamente para la fecha 2024-01-05.\n",
      "Datos guardados correctamente para la fecha 2024-01-06.\n",
      "Datos guardados correctamente para la fecha 2024-01-07.\n",
      "Datos guardados correctamente para la fecha 2024-01-08.\n",
      "Datos guardados correctamente para la fecha 2024-01-09.\n",
      "Datos guardados correctamente para la fecha 2024-01-10.\n",
      "Datos guardados correctamente para la fecha 2024-01-11.\n",
      "Datos guardados correctamente para la fecha 2024-01-12.\n",
      "Datos guardados correctamente para la fecha 2024-01-13.\n",
      "Datos guardados correctamente para la fecha 2024-01-14.\n",
      "Datos guardados correctamente para la fecha 2024-01-15.\n",
      "Datos guardados correctamente para la fecha 2024-01-16.\n",
      "Datos guardados correctamente para la fecha 2024-01-17.\n",
      "Datos guardados correctamente para la fecha 2024-01-18.\n",
      "Datos guardados correctamente para la fecha 2024-01-19.\n",
      "Datos guardados correctamente para la fecha 2024-01-20.\n",
      "Datos guardados correctamente para la fecha 2024-01-21.\n",
      "Datos guardados correctamente para la fecha 2024-01-22.\n",
      "Datos guardados correctamente para la fecha 2024-01-23.\n",
      "Datos guardados correctamente para la fecha 2024-01-24.\n",
      "Datos guardados correctamente para la fecha 2024-01-25.\n",
      "Datos guardados correctamente para la fecha 2024-01-26.\n",
      "Datos guardados correctamente para la fecha 2024-01-27.\n",
      "Datos guardados correctamente para la fecha 2024-01-28.\n",
      "Datos guardados correctamente para la fecha 2024-01-29.\n",
      "Datos guardados correctamente para la fecha 2024-01-30.\n",
      "Datos guardados correctamente para la fecha 2024-01-31.\n",
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "# 1_fetch_data.ipynb: Script para obtener datos de la API de TVMaze y guardarlos en formato JSON.\n",
    "\n",
    "# Crear carpeta json\n",
    "os.makedirs('./json', exist_ok=True)\n",
    "\n",
    "def fetch_and_save_data(date):\n",
    "    \"\"\"\n",
    "    Función para obtener datos de la API de TVMaze y guardarlos en formato JSON.\n",
    "    \"\"\"\n",
    "    url = f'http://api.tvmaze.com/schedule/web?date={date}'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        file_path = f'./json/{date}.json'\n",
    "\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(f'Datos guardados correctamente para la fecha {date}.')\n",
    "    else:\n",
    "        print(f'Error al obtener datos para la fecha {date}: {response.status_code}')\n",
    "\n",
    "\n",
    "# Fechas del 1 de enero al 31 de enero de 2024\n",
    "start_date = datetime(2024, 1, 1)\n",
    "end_date = datetime(2024, 1, 31)\n",
    "\n",
    "date_list = [(start_date + timedelta(days=x)).strftime('%Y-%m-%d') for x in range((end_date - start_date).days + 1)]\n",
    "\n",
    "# Obtener datos para cada día de enero de 2024\n",
    "for date in date_list:\n",
    "    fetch_and_save_data(date)\n",
    "\n",
    "print('Proceso completado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4996 entries, 0 to 4995\n",
      "Data columns (total 66 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   id                                          4996 non-null   int64  \n",
      " 1   url                                         4996 non-null   object \n",
      " 2   name                                        4996 non-null   object \n",
      " 3   season                                      4996 non-null   int64  \n",
      " 4   number                                      4958 non-null   float64\n",
      " 5   type                                        4996 non-null   object \n",
      " 6   airdate                                     4996 non-null   object \n",
      " 7   airtime                                     4996 non-null   object \n",
      " 8   airstamp                                    4996 non-null   object \n",
      " 9   runtime                                     4437 non-null   float64\n",
      " 10  image                                       0 non-null      float64\n",
      " 11  summary                                     1487 non-null   object \n",
      " 12  rating.average                              364 non-null    float64\n",
      " 13  _links.self.href                            4996 non-null   object \n",
      " 14  _links.show.href                            4996 non-null   object \n",
      " 15  _links.show.name                            4996 non-null   object \n",
      " 16  _embedded.show.id                           4996 non-null   int64  \n",
      " 17  _embedded.show.url                          4996 non-null   object \n",
      " 18  _embedded.show.name                         4996 non-null   object \n",
      " 19  _embedded.show.type                         4996 non-null   object \n",
      " 20  _embedded.show.language                     4658 non-null   object \n",
      " 21  _embedded.show.genres                       4996 non-null   object \n",
      " 22  _embedded.show.status                       4996 non-null   object \n",
      " 23  _embedded.show.runtime                      1017 non-null   float64\n",
      " 24  _embedded.show.averageRuntime               4594 non-null   float64\n",
      " 25  _embedded.show.premiered                    4996 non-null   object \n",
      " 26  _embedded.show.ended                        1849 non-null   object \n",
      " 27  _embedded.show.officialSite                 4438 non-null   object \n",
      " 28  _embedded.show.schedule.time                4996 non-null   object \n",
      " 29  _embedded.show.schedule.days                4996 non-null   object \n",
      " 30  _embedded.show.rating.average               743 non-null    float64\n",
      " 31  _embedded.show.weight                       4996 non-null   int64  \n",
      " 32  _embedded.show.network                      0 non-null      float64\n",
      " 33  _embedded.show.webChannel.id                4812 non-null   float64\n",
      " 34  _embedded.show.webChannel.name              4812 non-null   object \n",
      " 35  _embedded.show.webChannel.country.name      3179 non-null   object \n",
      " 36  _embedded.show.webChannel.country.code      3179 non-null   object \n",
      " 37  _embedded.show.webChannel.country.timezone  3179 non-null   object \n",
      " 38  _embedded.show.webChannel.officialSite      3679 non-null   object \n",
      " 39  _embedded.show.dvdCountry                   0 non-null      object \n",
      " 40  _embedded.show.externals.tvrage             185 non-null    float64\n",
      " 41  _embedded.show.externals.thetvdb            3461 non-null   float64\n",
      " 42  _embedded.show.externals.imdb               2260 non-null   object \n",
      " 43  _embedded.show.image.medium                 4737 non-null   object \n",
      " 44  _embedded.show.image.original               4737 non-null   object \n",
      " 45  _embedded.show.summary                      4182 non-null   object \n",
      " 46  _embedded.show.updated                      4996 non-null   int64  \n",
      " 47  _embedded.show._links.self.href             4996 non-null   object \n",
      " 48  _embedded.show._links.previousepisode.href  4996 non-null   object \n",
      " 49  _embedded.show._links.previousepisode.name  4996 non-null   object \n",
      " 50  _embedded.show.image                        0 non-null      float64\n",
      " 51  _embedded.show._links.nextepisode.href      538 non-null    object \n",
      " 52  _embedded.show._links.nextepisode.name      538 non-null    object \n",
      " 53  image.medium                                1267 non-null   object \n",
      " 54  image.original                              1267 non-null   object \n",
      " 55  _embedded.show.network.id                   563 non-null    float64\n",
      " 56  _embedded.show.network.name                 563 non-null    object \n",
      " 57  _embedded.show.network.country.name         563 non-null    object \n",
      " 58  _embedded.show.network.country.code         563 non-null    object \n",
      " 59  _embedded.show.network.country.timezone     563 non-null    object \n",
      " 60  _embedded.show.network.officialSite         193 non-null    object \n",
      " 61  _embedded.show.webChannel                   0 non-null      float64\n",
      " 62  _embedded.show.webChannel.country           0 non-null      float64\n",
      " 63  _embedded.show.dvdCountry.name              6 non-null      object \n",
      " 64  _embedded.show.dvdCountry.code              6 non-null      object \n",
      " 65  _embedded.show.dvdCountry.timezone          6 non-null      object \n",
      "dtypes: float64(15), int64(5), object(46)\n",
      "memory usage: 2.5+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_2480\\1246399053.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat(dataframes, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# 2_create_dataframe.ipynb: Script para leer los archivos JSON guardados y crear DataFrames de episodios y shows.\n",
    "\n",
    "# Crear la carpeta profiling\n",
    "os.makedirs('./profiling', exist_ok=True)\n",
    "\n",
    "# Directorio donde están guardados los archivos JSON\n",
    "json_folder = './json'\n",
    "dataframes = []\n",
    "\n",
    "# Leer todos los archivos JSON almacenados\n",
    "for filename in os.listdir(json_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(json_folder, filename)\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if isinstance(data, list):  # Verificar que el JSON sea una lista\n",
    "            df = pd.json_normalize(data)\n",
    "            dataframes.append(df)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "if dataframes:\n",
    "    full_df = pd.concat(dataframes, ignore_index=True)\n",
    "else:\n",
    "    raise Exception(\"No se encontraron archivos JSON válidos en la carpeta.\")\n",
    "\n",
    "# Mostrar información inicial del DataFrame\n",
    "full_df.info()\n",
    "full_df.head()\n",
    "\n",
    "# Crear DataFrame de episodios (episodes_df)\n",
    "episodes_columns = [\n",
    "    'id', 'url', 'name', 'season', 'number', 'type', 'airdate', 'airtime', 'airstamp', \n",
    "    'runtime', 'rating.average', '_links.self.href', '_links.show.href', '_links.show.name',\n",
    "    '_embedded.show.id'\n",
    "]\n",
    "\n",
    "episodes_df = full_df[episodes_columns].copy()\n",
    "\n",
    "# Separar información de episodios y renombrar columnas de episodios para consistencia\n",
    "episodes_df.rename(columns={\n",
    "    'id': 'episode_id',\n",
    "    'url': 'episode_url',\n",
    "    'name': 'episode_name',\n",
    "    'season': 'season_number',\n",
    "    'number': 'episode_number',\n",
    "    'type': 'episode_type',\n",
    "    'airdate': 'episode_airdate',\n",
    "    'airtime': 'episode_airtime',\n",
    "    'airstamp': 'episode_airstamp',\n",
    "    'runtime': 'episode_runtime',\n",
    "    'rating.average': 'episode_rating_average',\n",
    "    '_links.self.href': 'episode_self_href',\n",
    "    '_links.show.href': 'episode_show_href',\n",
    "    '_links.show.name': 'episode_show_name',\n",
    "    '_embedded.show.id': 'show_id'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame de shows (shows_df)\n",
    "shows_columns = [col for col in full_df.columns if col not in episodes_columns]\n",
    "if '_embedded.show.id' not in shows_columns and 'show_id' not in shows_columns:\n",
    "    shows_columns.append('_embedded.show.id')  # Añadir la columna que necesitas\n",
    "shows_df = full_df[shows_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4996 entries, 0 to 4995\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   episode_id              4996 non-null   int64  \n",
      " 1   episode_url             4996 non-null   object \n",
      " 2   episode_name            4996 non-null   object \n",
      " 3   season_number           4996 non-null   int64  \n",
      " 4   episode_number          4958 non-null   float64\n",
      " 5   episode_type            4996 non-null   object \n",
      " 6   episode_airdate         4996 non-null   object \n",
      " 7   episode_airtime         4996 non-null   object \n",
      " 8   episode_airstamp        4996 non-null   object \n",
      " 9   episode_runtime         4437 non-null   float64\n",
      " 10  episode_rating_average  364 non-null    float64\n",
      " 11  episode_self_href       4996 non-null   object \n",
      " 12  episode_show_href       4996 non-null   object \n",
      " 13  episode_show_name       4996 non-null   object \n",
      " 14  show_id                 4996 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(9)\n",
      "memory usage: 585.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4996 entries, 0 to 4995\n",
      "Data columns (total 52 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   image                             0 non-null      float64\n",
      " 1   summary                           1487 non-null   object \n",
      " 2   show_url                          4996 non-null   object \n",
      " 3   show_name                         4996 non-null   object \n",
      " 4   show_type                         4996 non-null   object \n",
      " 5   show_language                     4658 non-null   object \n",
      " 6   show_genres                       4996 non-null   object \n",
      " 7   show_status                       4996 non-null   object \n",
      " 8   show_runtime                      1017 non-null   float64\n",
      " 9   show_average_runtime              4594 non-null   float64\n",
      " 10  show_premiered                    4996 non-null   object \n",
      " 11  show_ended                        1849 non-null   object \n",
      " 12  show_official_site                4438 non-null   object \n",
      " 13  show_schedule_time                4996 non-null   object \n",
      " 14  show_schedule_days                4996 non-null   object \n",
      " 15  show_rating_average               743 non-null    float64\n",
      " 16  show_weight                       4996 non-null   int64  \n",
      " 17  show_network                      0 non-null      float64\n",
      " 18  show_webChannel_id                4812 non-null   float64\n",
      " 19  show_webChannel_name              4812 non-null   object \n",
      " 20  show_webChannel_country_name      3179 non-null   object \n",
      " 21  show_webChannel_country_code      3179 non-null   object \n",
      " 22  show_webChannel_country_timezone  3179 non-null   object \n",
      " 23  show_webChannel_officialSite      3679 non-null   object \n",
      " 24  _embedded.show.dvdCountry         0 non-null      object \n",
      " 25  show_tvrage                       185 non-null    float64\n",
      " 26  show_thetvdb                      3461 non-null   float64\n",
      " 27  show_imdb                         2260 non-null   object \n",
      " 28  show_image_medium                 4737 non-null   object \n",
      " 29  show_image_original               4737 non-null   object \n",
      " 30  show_summary                      4182 non-null   object \n",
      " 31  show_updated                      4996 non-null   int64  \n",
      " 32  show_self_href                    4996 non-null   object \n",
      " 33  show_previousepisode_href         4996 non-null   object \n",
      " 34  show_previousepisode_name         4996 non-null   object \n",
      " 35  show_image                        0 non-null      float64\n",
      " 36  show_nextepisode_href             538 non-null    object \n",
      " 37  show_nextepisode_name             538 non-null    object \n",
      " 38  image.medium                      1267 non-null   object \n",
      " 39  image.original                    1267 non-null   object \n",
      " 40  show_network_id                   563 non-null    float64\n",
      " 41  show_network_name                 563 non-null    object \n",
      " 42  show_network_country_name         563 non-null    object \n",
      " 43  show_network_country_code         563 non-null    object \n",
      " 44  show_network_country_timezone     563 non-null    object \n",
      " 45  show_network_official_site        193 non-null    object \n",
      " 46  show_webChannel                   0 non-null      float64\n",
      " 47  show_webChannel_country           0 non-null      float64\n",
      " 48  show_dvdCountry_name              6 non-null      object \n",
      " 49  show_dvdCountry_code              6 non-null      object \n",
      " 50  show_dvdCountry_timezone          6 non-null      object \n",
      " 51  show_id                           4996 non-null   int64  \n",
      "dtypes: float64(12), int64(3), object(37)\n",
      "memory usage: 2.0+ MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affc39f0a5d5474b8ee8197f2e1252ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfddaa6ba34748ae9ad10aebd041a510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85db25ee05341ee848a8c11d8f32b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f845be20983b487b9264d27385942e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a305d30a87f845ec9da2b3a2c707e50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ydata_profiling\\model\\pandas\\summary_pandas.py:39: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  series = series.fillna(np.nan)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688c8b9394634698a770585edf6b3c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43632b1c55341cdb8f1537e0ab58eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ce2651994f4f19b19fec69df2274b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling generado para ambos DataFrames y almacenado en la carpeta 'profiling/'.\n"
     ]
    }
   ],
   "source": [
    "# Separar información de shows sin duplicados y renombrar columnas de shows para consistencia\n",
    "shows_df.rename(columns={\n",
    "    '_embedded.show.id': 'show_id',\n",
    "    '_embedded.show.url': 'show_url',\n",
    "    '_embedded.show.name': 'show_name',\n",
    "    '_embedded.show.type': 'show_type',\n",
    "    '_embedded.show.language': 'show_language',\n",
    "    '_embedded.show.genres': 'show_genres',\n",
    "    '_embedded.show.status': 'show_status',\n",
    "    '_embedded.show.runtime': 'show_runtime',\n",
    "    '_embedded.show.averageRuntime': 'show_average_runtime',\n",
    "    '_embedded.show.premiered': 'show_premiered',\n",
    "    '_embedded.show.ended': 'show_ended',\n",
    "    '_embedded.show.officialSite': 'show_official_site',\n",
    "    '_embedded.show.schedule.time': 'show_schedule_time',\n",
    "    '_embedded.show.schedule.days': 'show_schedule_days',\n",
    "    '_embedded.show.rating.average': 'show_rating_average',\n",
    "    '_embedded.show.weight': 'show_weight',\n",
    "    '_embedded.show.network': 'show_network',\n",
    "    '_embedded.show.webChannel.id': 'show_webChannel_id',\n",
    "    '_embedded.show.webChannel.name': 'show_webChannel_name',\n",
    "    '_embedded.show.webChannel.country.name': 'show_webChannel_country_name',\n",
    "    '_embedded.show.webChannel.country.code': 'show_webChannel_country_code',\n",
    "    '_embedded.show.webChannel.country.timezone': 'show_webChannel_country_timezone',\n",
    "    '_embedded.show.webChannel.officialSite': 'show_webChannel_officialSite',\n",
    "    '_embedded.show.externals.tvrage': 'show_tvrage',\n",
    "    '_embedded.show.externals.thetvdb': 'show_thetvdb',\n",
    "    '_embedded.show.externals.imdb': 'show_imdb',\n",
    "    '_embedded.show.image.medium': 'show_image_medium',\n",
    "    '_embedded.show.image.original': 'show_image_original',\n",
    "    '_embedded.show.summary': 'show_summary',\n",
    "    '_embedded.show.updated': 'show_updated',\n",
    "    '_embedded.show._links.self.href': 'show_self_href',\n",
    "    '_embedded.show._links.previousepisode.href': 'show_previousepisode_href',\n",
    "    '_embedded.show._links.previousepisode.name': 'show_previousepisode_name',\n",
    "    '_embedded.show._links.nextepisode.href': 'show_nextepisode_href',\n",
    "    '_embedded.show._links.nextepisode.name': 'show_nextepisode_name',\n",
    "    '_embedded.show.network.id': 'show_network_id',\n",
    "    '_embedded.show.network.name': 'show_network_name',\n",
    "    '_embedded.show.network.country.name': 'show_network_country_name',\n",
    "    '_embedded.show.network.country.code': 'show_network_country_code',\n",
    "    '_embedded.show.network.country.timezone': 'show_network_country_timezone',\n",
    "    '_embedded.show.network.officialSite': 'show_network_official_site',\n",
    "    '_embedded.show.webChannel': 'show_webChannel',\n",
    "    '_embedded.show.webChannel.country': 'show_webChannel_country',\n",
    "    '_embedded.show.dvdCountry.name': 'show_dvdCountry_name',\n",
    "    '_embedded.show.dvdCountry.code': 'show_dvdCountry_code',\n",
    "    '_embedded.show.dvdCountry.timezone': 'show_dvdCountry_timezone',\n",
    "    '_embedded.show.image': 'show_image'\n",
    "}, inplace=True)\n",
    "\n",
    "episodes_df.info()\n",
    "shows_df.info()\n",
    "\n",
    "# Eliminar duplicados por show_id\n",
    "shows_df = shows_df.drop_duplicates(subset=['show_id'])\n",
    "\n",
    "# Generar profiling para `episodes_df`\n",
    "profile_episodes = ProfileReport(episodes_df, title=\"Reporte de Profiling - Episodios\", explorative=True)\n",
    "profile_episodes.to_file(\"./profiling/tvmaze_profiling_episodes.html\")\n",
    "\n",
    "# Generar profiling para `shows_df`\n",
    "profile_shows = ProfileReport(shows_df, title=\"Reporte de Profiling - Shows\", explorative=True)\n",
    "profile_shows.to_file(\"./profiling/tvmaze_profiling_shows.html\")\n",
    "\n",
    "print(\"Profiling generado para ambos DataFrames y almacenado en la carpeta 'profiling/'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          [Drama, Comedy, Romance]\n",
      "10    [Drama, Comedy, Supernatural]\n",
      "12    [Comedy, Adventure, Children]\n",
      "13                [Comedy, Fantasy]\n",
      "25                         [Comedy]\n",
      "Name: show_genres, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verificar cómo se ve la columna actualmente\n",
    "print(shows_df['show_genres'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpieza de datos completada y archivos guardados con compresión Snappy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_2480\\3393694662.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  shows_df['show_genres'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 3_data_cleaning.ipynb: Script para limpiar los DataFrames de episodios y shows, eliminando duplicados y valores nulos.\n",
    "\n",
    "# Crear la carpeta 'data'\n",
    "data_folder = './data'\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Limpiar episodios\n",
    "episodes_df = episodes_df.drop_duplicates(subset=['episode_id'])\n",
    "\n",
    "# Limpiar shows\n",
    "shows_df = shows_df.drop_duplicates(subset=['show_id'])\n",
    "\n",
    "# Episodios que deben tener un runtime válido\n",
    "episodes_df = episodes_df.dropna(subset=['episode_runtime'])\n",
    "\n",
    "# Rellenar con \"Unknown\" en lugar de NaN\n",
    "shows_df['show_genres'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Eliminar columnas innecesarias de episodios y shows\n",
    "shows_df.drop(['image', 'show_image', 'show_network', 'show_webChannel_country'], axis=1, inplace=True)\n",
    "\n",
    "# Eliminar columnas completamente vacías (0 registros válidos)\n",
    "episodes_df = episodes_df.dropna(axis=1, how='all')\n",
    "shows_df = shows_df.dropna(axis=1, how='all')\n",
    "\n",
    "# 🔄 Guardar DataFrames limpios en archivos Parquet con compresión Snappy\n",
    "episodes_df.to_parquet(f'{data_folder}/episodes_cleaned.parquet', compression='snappy')\n",
    "shows_df.to_parquet(f'{data_folder}/shows_cleaned.parquet', compression='snappy')\n",
    "\n",
    "print(\"Limpieza de datos completada y archivos guardados con compresión Snappy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de celdas que son listas o arrays: 0\n",
      "<class 'pandas.core.series.Series'>\n",
      "DataFrames guardados exitosamente en la base de datos SQLite.\n"
     ]
    }
   ],
   "source": [
    "# 4_save_to_sql.ipynb: Script para guardar los DataFrames en una base de datos SQLite.\n",
    "\n",
    "# Crear la carpeta db\n",
    "db_folder = './db'\n",
    "os.makedirs(db_folder, exist_ok=True)\n",
    "\n",
    "# Conectar a la base de datos SQLite\n",
    "conn = sqlite3.connect(f'{db_folder}/tvmaze_data.db')\n",
    "\n",
    "# Cargar DataFrames limpios desde archivos Parquet\n",
    "episodes_df_parquet = pd.read_parquet('./data/episodes_cleaned.parquet')\n",
    "shows_df_parquet = pd.read_parquet('./data/shows_cleaned.parquet')\n",
    "\n",
    "\n",
    "\n",
    "# Revisar si alguna celda de show_genres es un ndarray o una lista\n",
    "invalid_types = shows_df_parquet.apply(lambda x: isinstance(x, (list, tuple, np.ndarray))).sum()\n",
    "print(f\"Cantidad de celdas que son listas o arrays: {invalid_types}\")\n",
    "print(type(shows_df_parquet.iloc[0]))\n",
    "\n",
    "# Función para convertir cualquier tipo de dato a un formato serializable\n",
    "def convert_to_json(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        # Convertir ndarray a lista\n",
    "        x = x.tolist()\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        # Convertir listas y tuplas a JSON strings\n",
    "        return json.dumps(x)\n",
    "    return x\n",
    "\n",
    "# Aplicar la conversión a la columna 'show_genres'\n",
    "shows_df_parquet = shows_df_parquet.apply(convert_to_json)\n",
    "\n",
    "# Guardar DataFrames en la base de datos\n",
    "episodes_df_parquet.to_sql('episodes', conn, if_exists='replace', index=False)\n",
    "shows_df_parquet.to_sql('shows', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(\"DataFrames guardados exitosamente en la base de datos SQLite.\")\n",
    "\n",
    "# Cerrar la conexión\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                 [Drama, Comedy, Romance]\n",
      "10           [Drama, Comedy, Supernatural]\n",
      "12           [Comedy, Adventure, Children]\n",
      "13                       [Comedy, Fantasy]\n",
      "25                                [Comedy]\n",
      "33                                [Comedy]\n",
      "35                        [Drama, History]\n",
      "40    [Children, Fantasy, Science-Fiction]\n",
      "50             [Adventure, Anime, Fantasy]\n",
      "51     [Action, Adventure, Anime, Fantasy]\n",
      "Name: show_genres, dtype: object\n",
      "show_genres\n",
      "<class 'numpy.ndarray'>    729\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo parquet\n",
    "shows_df_parquet = pd.read_parquet('./data/shows_cleaned.parquet')\n",
    "\n",
    "# Revisar los primeros registros de la columna 'show_genres'\n",
    "print(shows_df_parquet['show_genres'].head(10))\n",
    "\n",
    "# Revisar los tipos de datos presentes en 'show_genres'\n",
    "type_counts = shows_df_parquet['show_genres'].apply(lambda x: type(x)).value_counts()\n",
    "print(type_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                 [Drama, Comedy, Romance]\n",
      "10           [Drama, Comedy, Supernatural]\n",
      "12           [Comedy, Adventure, Children]\n",
      "13                       [Comedy, Fantasy]\n",
      "25                                [Comedy]\n",
      "33                                [Comedy]\n",
      "35                        [Drama, History]\n",
      "40    [Children, Fantasy, Science-Fiction]\n",
      "50             [Adventure, Anime, Fantasy]\n",
      "51     [Action, Adventure, Anime, Fantasy]\n",
      "Name: show_genres, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def convert_show_genres(value):\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            # Si la columna fue guardada como un string JSON, lo convertimos a lista\n",
    "            genres = ast.literal_eval(value)\n",
    "            if isinstance(genres, list):\n",
    "                return genres\n",
    "        except:\n",
    "            pass\n",
    "    elif isinstance(value, np.ndarray):\n",
    "        # Si se guardó como numpy array, convertir a lista\n",
    "        return value.tolist()\n",
    "    elif isinstance(value, bytes):\n",
    "        try:\n",
    "            # Si es un bytes, intentamos decodificarlo\n",
    "            decoded_value = value.decode('utf-8')\n",
    "            genres = ast.literal_eval(decoded_value)\n",
    "            if isinstance(genres, list):\n",
    "                return genres\n",
    "        except:\n",
    "            pass\n",
    "    return []  # Si falla, devolver una lista vacía\n",
    "\n",
    "# Aplicar la conversión\n",
    "shows_df_parquet['show_genres'] = shows_df_parquet['show_genres'].apply(convert_show_genres)\n",
    "\n",
    "# Verificar el contenido nuevamente\n",
    "print(shows_df_parquet['show_genres'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime Promedio: 42.25637181409295 minutos\n",
      "Conteo de géneros: show_genres\n",
      "Drama              157\n",
      "Comedy             123\n",
      "Romance             73\n",
      "Adventure           70\n",
      "Fantasy             69\n",
      "Action              59\n",
      "Crime               45\n",
      "Anime               41\n",
      "Mystery             31\n",
      "Thriller            29\n",
      "History             26\n",
      "Children            25\n",
      "Food                22\n",
      "Sports              20\n",
      "Travel              18\n",
      "Music               17\n",
      "Family              15\n",
      "Science-Fiction     13\n",
      "War                 12\n",
      "Nature              10\n",
      "Supernatural         8\n",
      "Medical              8\n",
      "Horror               7\n",
      "DIY                  7\n",
      "Legal                4\n",
      "Adult                3\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Dominios únicos encontrados:\n",
      "www.ivi.ru\n",
      "okko.tv\n",
      "wink.ru\n",
      "kion.ru\n",
      "b''\n",
      "premier.one\n",
      "iview.abc.net.au\n",
      "v.qq.com\n",
      "v.youku.com\n",
      "w.mgtv.com\n",
      "asiapoisk.com\n",
      "www.bbc.co.uk\n",
      "www.hotstar.com\n",
      "smotrim.ru\n",
      "youtube.com\n",
      "program.imbc.com\n",
      "elisaviihde.fi\n",
      "play.tv2.no\n",
      "tvn.cjenm.com\n",
      "www.amazon.co.uk\n",
      "www.viceland.com\n",
      "www.wowpresentsplus.com\n",
      "www.netflix.com\n",
      "www.iq.com\n",
      "v.youku.tv\n",
      "www.paramountplus.com\n",
      "www.youtube.com\n",
      "www.primevideo.com\n",
      "shahid.mbc.net\n",
      "discoveryplus.in\n",
      "www.univision.com\n",
      "www.arte.tv\n",
      "tv.apple.com\n",
      "www.cbc.ca\n",
      "abcnews.go.com\n",
      "www.youku.tv\n",
      "www.knowledgekids.ca\n",
      "www.peacocktv.com\n",
      "roosterteeth.com\n",
      "watch.wwe.com\n",
      "www.nbcnews.com\n",
      "www.cbsnews.com\n",
      "gtst.nl\n",
      "tv.nrk.no\n",
      "www.tv4play.se\n",
      "www.wwe.com\n",
      "magnolia.com\n",
      "start.ru\n",
      "m.youku.com\n",
      "vk.com\n",
      "viaplay.dk\n",
      "www.disneyplus.com\n",
      "www.amazon.com\n",
      "odekake-kozame.com\n",
      "www.iqiyi.com\n",
      "www.cnn.com\n",
      "www.joerogan.com\n",
      "www.sbs.com.au\n",
      "www.today.com\n",
      "www.dropout.tv\n",
      "www.discoveryplus.com\n",
      "abc.com\n",
      "voyo.nova.cz\n",
      "www.cwtv.com\n",
      "twit.tv\n",
      "www.foxnews.com\n",
      "weibo.com\n",
      "www.bilibili.com\n",
      "www.kuaishou.com\n",
      "tv3.ru\n",
      "www.srf.ch\n",
      "warhammertv.com\n",
      "disneynow.com\n",
      "bleacherreport.com\n",
      "www.fubo.tv\n",
      "www.pokergo.com\n",
      "www.svtplay.se\n",
      "www.outtvgo.com\n",
      "hd.kinopoisk.ru\n",
      "www.ddtpro.com\n",
      "so.youku.com\n",
      "www.itv.com\n",
      "www.sonyliv.com\n",
      "www.jiocinema.com\n",
      "www.njpw1972.com\n",
      "www.mtv.fi\n",
      "ver.movistarplus.es\n",
      "www.hbomax.com\n",
      "www.britbox.com\n",
      "voyo.si\n",
      "stories.showmax.com\n",
      "www.dndbeyond.com\n",
      "www.alaraby.com\n",
      "www.blutv.com\n",
      "network.wwe.com\n",
      "www.bet.plus\n",
      "allblk.tv\n",
      "www.sundancenow.com\n",
      "www.hulu.com\n",
      "www.zdf.de\n",
      "www.channel4.com\n",
      "www.dr.dk\n",
      "www.tvnow.de\n",
      "www.crave.ca\n",
      "rosenbergreport.tv\n",
      "seasonvar.ru\n",
      "list.youku.com\n",
      "www.tving.com\n",
      "laftel.net\n",
      "www.exxen.com\n",
      "v2.videoland.com\n",
      "www.goplay.be\n",
      "www.facebook.com\n",
      "sic.pt\n",
      "vidol.tv\n",
      "opto.sic.pt\n",
      "www.votvot.tv\n",
      "www.swearnet.com\n",
      "www.sho.com\n",
      "app.pureflix.com\n",
      "www.dailywire.com\n",
      "superchannel.ca\n",
      "vkvideo.ru\n",
      "www.asiasuperyoung.xyz\n",
      "talesofweddingrings-anime.jp\n",
      "sololeveling-anime.net\n",
      "www.raiplay.it\n",
      "www.pbs.org\n",
      "amasupercross.com\n",
      "vod.tvp.pl\n",
      "play.max.com\n",
      "ukrainer.net\n",
      "www.adweek.com\n",
      "www.thezeusnetwork.com\n",
      "www.gain.tv\n",
      "www.goldenglobes.com\n",
      "www.5-tv.ru\n",
      "pro-tv.info\n",
      "www.nta.ua\n",
      "kusuriyanohitorigoto.jp\n",
      "kanaten-anime.com\n",
      "www.foxbusiness.com\n",
      "www.bravotv.com\n",
      "www.tv3.dk\n",
      "www.atopthefourthwall.com\n",
      "www.nbc.com\n",
      "nation.foxnews.com\n",
      "goplay.be\n",
      "www.ceskatelevize.cz\n",
      "www.insideofyoupodcast.com\n",
      "lexfridman.com\n",
      "www.shudder.com\n",
      "tubitv.com\n",
      "www.france.tv\n",
      "wetv.vip\n",
      "frieren-anime.jp\n",
      "www.nfl.com\n",
      "sengoku-youko.com\n",
      "www.cc.com\n",
      "www.bac.org.il\n",
      "www.gagaoolala.com\n",
      "elcinema.com\n",
      "critrole.com\n",
      "www.aetv.com\n",
      "infoman.radio-canada.ca\n",
      "www.joyn.de\n",
      "www.angel.com\n",
      "www.trueid.net\n",
      "simonscat.com\n",
      "m.youtube.com\n",
      "www.cbs.com\n",
      "www.harlemglobetrotters.com\n",
      "vyzit-v-dubae.tnt-online.ru\n",
      "tnt-online.ru\n",
      "premium.atresplayer.com\n",
      "www.ufc.com\n",
      "www.oneplay.cz\n",
      "www.motortrend.com\n",
      "www.mpt.org\n",
      "auvio.rtbf.be\n",
      "stopgame.ru\n",
      "www.talkvillepodcast.com\n",
      "www.stan.com.au\n",
      "www.ruutu.fi\n",
      "galgos.movistarplus.es\n",
      "skamitalia.timvision.it\n",
      "ici.tou.tv\n",
      "www.watchtrublu.com\n",
      "www.amazon.in\n",
      "www.ardmediathek.de\n",
      "therokuchannel.roku.com\n",
      "www.max.com\n",
      "sympacool.com\n",
      "povysaia-gradus.tnt-online.ru\n",
      "viaplay.no\n",
      "heyqween.tv\n",
      "plus.rtl.de\n",
      "www.kinopoisk.ru\n",
      "vtmgo.be\n",
      "www.stream.cz\n",
      "flameserial.ru\n",
      "tv.nova.cz\n",
      "vmesteproject.ru\n",
      "www.miguvideo.com\n",
      "independentwrestling.tv\n",
      "www.laisves.tv\n",
      "megogo.net\n",
      "mult.ru\n",
      "kurzgesagt.org\n",
      "tv.line.me\n",
      "watcha.com\n",
      "tv.tv2.dk\n",
      "gem.cbc.ca\n",
      "disneyplus.com\n",
      "www.espn.com\n"
     ]
    }
   ],
   "source": [
    "# 5_analysis.ipynb: Script para realizar análisis sobre los DataFrames de episodios y shows.\n",
    "\n",
    "# 1. Calcular Runtime Promedio (averageRuntime)\n",
    "average_runtime = shows_df_parquet['show_average_runtime'].mean()\n",
    "print(f\"Runtime Promedio: {average_runtime} minutos\")\n",
    "\n",
    "\n",
    "# 2. Conteo de shows por género\n",
    "exploded_genres = shows_df_parquet.explode('show_genres')\n",
    "genre_counts = exploded_genres['show_genres'].value_counts()\n",
    "print(f\"Conteo de géneros: {genre_counts}\")\n",
    "\n",
    "\n",
    "# 3. Listar dominios únicos del sitio oficial\n",
    "def extract_domain(url):\n",
    "    try:\n",
    "        return urlparse(url).netloc\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "shows_df_parquet['domain'] = shows_df_parquet['show_official_site'].apply(extract_domain)\n",
    "unique_domains = shows_df_parquet['domain'].dropna().unique()\n",
    "print(\"\\n Dominios únicos encontrados:\")\n",
    "for domain in unique_domains:\n",
    "    print(domain)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
